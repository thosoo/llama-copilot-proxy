#!/usr/bin/env node

// Test to ensure our debugging logs for /api/show are working

console.log('üß™ Testing /api/show debug logging...');

async function testApiShowLogging() {
  try {
    console.log('üì° Making /api/show request to proxy...');
    
    // Make request to the proxy, not directly to llama-server
    const res = await fetch('http://localhost:11434/api/show', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ 
        name: "/home/thaison/.cache/llama.cpp/Qwen_Qwen3-4B-GGUF_Qwen3-4B-Q8_0.gguf" 
      })
    });
    
    console.log('‚úÖ Response status:', res.status);
    
    const data = await res.json();
    console.log('üì¶ Response received with', Object.keys(data).length, 'keys');
    
    console.log('‚úÖ /api/show proxy test completed - check proxy logs for debug output');
    
  } catch (err) {
    console.error('‚ùå /api/show proxy test failed:', err.message);
  }
}

testApiShowLogging();
